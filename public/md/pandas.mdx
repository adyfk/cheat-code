---
title: "Pandas"
version: "1.4.0"
versionLink: "https://pypi.org/project/pandas"
category: "Library"
language: "Python"
used: ['']
author: "Adi Fatkhurozi"
authorLink: "https://github.com/adyfk"
description: "pandas is a Python package that provides fast, flexible, and expressive data structures designed to make working with `relational` or `labeled` data both easy and intuitive."
updateAt: "9/2/2022 20:5:00"
createdAt: "3/1/2022 00:00:00"
---

## Getting Started

### Install 
```bash
  pip install pandas
```

### Use
```py
  import pandas as pd

  print(pd.__version__)
```

## Series

### Create Series
```py 
  a = [1, 7, 2]
  
  # Create Pandas Series
  myvar = pd.Series(a)
  print(myvar)
  # 0    1
  # 1    7
  # 2    2
  print(myvar[0]) # 1 
```

### Add Label to Series
```py
  # Add Label to Series
  myvar = pd.Series(a, index = ["x", "y", "z"])
  print(myvar)
  # x    1
  # y    7
  # z    2
  print(myvar['x']) # 1
```

### Key / Value Object as Series

```py
  calories = {"day1": 420, "day2": 380, "day3": 390}

  # Key / Value Object as Series
  myvar = pd.Series(calories)  
  print(myvar)
  # day1    420
  # day2    380
  # day3    390

  myvar = pd.Series(calories, index = ["day1", "day2"])
  print(myvar)
  # day1    420
  # day2    380
```

## DataFrame
attribute `inplace` mean affect to real data

### Load DataFrame 
```py
  data = {
    "calories": [420, 380, 390],
    "duration": [50, 40, 45]
  }
  # Load data into a DataFrame object
  df = pd.DataFrame(data)
```

### Named Columns
```py
  data = { "calories": [420, 380, 390], "duration": [50, 40, 45] }
  df = pd.DataFrame(data, columns = ["x", "y"])
  print(df)
  #           x         y
  # 0       420        50
  # 1       380        40
  # 2       390        45
```

### Named Indexes
```py 
  data = { "calories": [420, 380, 390], "duration": [50, 40, 45] }
  df = pd.DataFrame(data, index = ["day1", "day2", "day3"])
  print(df)
  #       calories  duration
  # day1       420        50
  # day2       380        40
  # day3       390        45
```

### Reshaping Data
<img src='/assets/pandas/reshape.png' alt='Reshape Data' />

```py
  # order rows by values of a column (higt to low)
  df.sort_values('mpg', ascending=Flase)
  # sort by index dataframe
  df.sort_index()
  # reset index to number,  columns to number
  df.reset_index()

  # rename the columns
  df.rename(colums={'y':'Year'})
  # drop columns 
  df.drop(columns['x','y'])
```
###
### Subset Obeservatios - rows
```py
  df[df.Lenght > 7] # filtering data-frame
  
  # remove duplicate rows (onl considers columns)
  df.drop_duplicates(inplace=True)
  # Randomly select fraction rows
  df.sample(frac=0.5)
  # Select and Order top n entries
  df.nlargest(n, 'value')
  # Select and Order bottom n entries
  df.nsmallest(n, 'value')
  # print top 5 rows
  print(df.head())
  # print last 5 rows
  print(df.tail()) 
  # dataset information
  print(df.info()) 
  # print to string
  print(df.to_string())
```

### Subset Variables - columns 
```py
  # Select multiple columns with specific names
  df[['width', 'length', 'species']]
  # Seelct single columns
  df['width'] or df.width
  # Select column whose name matches regex
  df.filter(regex='regex')
```

### Subset - rows and columns
```py
  # Use df.loc[] and df.iloc[] to select only rows, only columns or both
  # Use df.at[] and df.iat[] to access a single value by row and column.

  # select row 0 and 2
  df.loc[[0, 2]]
  # select rows 10-20
  df.iloc[10:20]
  # seelct columns in positions 1,2,5 first column is 0
  df.iloc[:, [1,2,5]]
  # select all columns between x2 and x4 (inclusive)
  df.loc[:,'x2': 'x4']
  # select rows meeting logical condition, and only spesicif columns
  df.loc[df['a'] > 10, ['a', 'b']]
  # access single value by index
  df.iat[1,2]
  # access single value by label
  df.at[4,'A']
```

### Summarize Data 
```py
  # count number of rows with each unique value of variable
  df['w'].value_counts()
  # rows count
  lent(df)
  # of distinct values in a column.
  df['w'].nunique()
  # basic describe
  df.describe()
  # math
  df.sum()
  df.count()
  df.min()
  df.max()
  df.median()
  df.mean()
  df.std()
  df.apply(callback)
```

### Import Files 
```py 
  df = pd.read_csv('data.csv')
  # pd.options.display.max_rows = 9999
```

### Replace Data

```py
  df['Date'] = pd.to_datetime(df['Date'])
  # Remove rows with a NULL value in the "Date" column:
  df.dropna(subset=['Date'], inplace = True)

  # updating all column
  for x in df.index:
    if df.loc[x, "Duration"] > 120:
      df.loc[x, "Duration"] = 120

  # removing rows
  for x in df.index:
    if df.loc[x, "Duration"] > 120:
      df.drop(x, inplace = True)
```

### Cleaning NAN / NULL
```py
  # Drop row  ----------------------------------------
  # return new data (remove row has NaN)
  df.dropna()
  # inplace means affect to real data (remove row has NaN)
  df.dropna(inplace = True)
  # replace NaN with (value)
  df.fillna(130, inplace = True)  
  # Delete Duplicate Row
  df.drop_duplicates(inplace = True)
```

### Combine Data Sets
```py
  # basic like join query SQL
  # join matchin rows from df2 to df1 with col=x1
  pd.merge(df1, df2, how='left', on='x1')
  # join data , only rows in both side
  pd.merge(df1, df2, how='inner', on='x1')
  # join data , all values, and rows
  pd.merge(df1, df2, how='outer', on='x1')
```

### Grouping Data
```py
  # groupby columns
  df.groupby(by="col")
  # groupby index
  df.groupby(level='ind')
```

###
### Finding Relationships
```py
  # The corr() method calculates the relationship between each column 
  # in your data set.

  print(df.corr())
```